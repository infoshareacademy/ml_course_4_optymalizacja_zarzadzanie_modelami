{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt\n",
    "\n",
    "źródło danych: https://www.kaggle.com/datasets/taweilo/loan-approval-classification-data\n",
    "\n",
    "Dane zawierają informacje z wniosków kredytowych.\n",
    "\n",
    "Cel biznesowy: Stworzenie modelu, dzięki któremu przed złożeniem wniosku kredytowego, znamy decyzje, co pozwoli na nie tracenie czasu i procesowanie odpowiednich klientów.\n",
    "\n",
    "Założenie: y to akceptacja i uruchomienie kredytu.\n",
    "\n",
    "1. Dokonaj wstepnej analizy zbiory.\n",
    "2. Wytypuj zmienne do modelowania.\n",
    "3. Dokonaj potrzebnych przekształceń.\n",
    "4. Zoptymalizuj model.\n",
    "5. Stwórz symulację optymalizacji punktu cut-off wiedząc,że:\n",
    "    - False positive to strata banku w postaci czasu poświęconego przez pracownika - szacujemy stratę w wysokości 50.\n",
    "    - False negative to strata banku w wysokości  (loan_int_rate / 100 ) * loan_amnt (przyblizenie) - przybliżenie zysku banku, gdyby złożyć wniosek i klient by uruchomił kredyt.\n",
    "    - True positive to zysk w wysokości (loan_int_rate / 100 ) * loan_amnt\n",
    "    - True negative to oszczędność 50 jednostek.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/loan_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dokonaj wstepnej analizy zbioru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(exclude='object').corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_plot = ['loan_percent_income', 'loan_int_rate','person_income','loan_amnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols_to_plot:\n",
    "    sns.kdeplot(data=df,x=i,hue = df['loan_status'], common_norm=False)\n",
    "    plt.title(f'{i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.select_dtypes(include = 'object').columns\n",
    "for i in cols:\n",
    "    print(df[i].value_counts())\n",
    "    print(df[[i, 'loan_status']].groupby(i).mean())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_model = df[df['previous_loan_defaults_on_file']=='No'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_to_model.select_dtypes(include = 'object').columns\n",
    "for i in cols:\n",
    "    print(df_to_model[i].value_counts())\n",
    "    print(df_to_model[[i, 'loan_status']].groupby(i).mean())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Wytypuj zmienne do modelowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_encode = ['person_education','loan_intent','person_home_ownership']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False).fit(df_to_model[cols_to_encode])\n",
    "res = ohe.transform(df_to_model[cols_to_encode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_model = df_to_model.join(pd.DataFrame(data=res,columns = ohe.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = abs(df_to_model.select_dtypes(exclude='object').corr())['loan_status']\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = list(corr[(corr>0.05) & (corr <1)].index)\n",
    "x_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Zoptymalizuj model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(df_to_model[x_names], df_to_model['loan_status'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_fun(learning_rate, min_samples_leaf, n_estimators):\n",
    "    min_samples_leaf = int(round(min_samples_leaf))\n",
    "    n_estimators = int(round(n_estimators))\n",
    "    model = GradientBoostingClassifier(learning_rate=learning_rate,\n",
    "                                       min_samples_leaf=min_samples_leaf,\n",
    "                                       n_estimators=n_estimators).fit(train_x,train_y)\n",
    "    score = cross_val_score(model, train_x, train_y, cv=3, scoring = 'roc_auc' ).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"learning_rate\": [0.01,0.8],\n",
    "          \"min_samples_leaf\": [5,50],\n",
    "          \"n_estimators\": [20,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization = BayesianOptimization(f = opt_fun,\n",
    "                                    pbounds = params,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization.maximize(n_iter=10, init_points=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = optimization.max['params']\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['min_samples_leaf'] = int(round(best_params['min_samples_leaf']))\n",
    "best_params['n_estimators'] = int(round(best_params['n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(**best_params).fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict_proba(train_x)[:,1]\n",
    "test_pred = model.predict_proba(test_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_train  = round(roc_auc_score(train_y,train_pred),3)\n",
    "auc_test = round(roc_auc_score(test_y,test_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_train, tpr_train, thresholds_train = roc_curve(train_y,train_pred)\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(test_y,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_train,tpr_train,label = 'train')\n",
    "plt.plot(fpr_test, tpr_test, label = 'test')\n",
    "plt.plot(np.arange(0,1,0.01), np.arange(0,1,0.01),'--')\n",
    "plt.legend()\n",
    "plt.annotate(f'AUC train: {auc_train}',xy=[0.2,0.8])\n",
    "plt.annotate(f'AUC test: {auc_test}', xy=[0.2,0.75])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Stwórz symulację optymalizacji punktu cut-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- False positive to strata banku w postaci czasu poświęconego przez pracownika - szacujemy stratę w wysokości 50.\n",
    "- False negative to strata banku w wysokości  (loan_int_rate / 100 ) * loan_amnt (przyblizenie) - przybliżenie zysku banku, gdyby złożyć wniosek i klient by uruchomił kredyt.\n",
    "- True positive to zysk w wysokości (loan_int_rate / 100 ) * loan_amnt\n",
    "- True negative to oszczędność 50 jednostek.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = -50 \n",
    "tn = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = test_x.copy()\n",
    "test['pred'] = test_pred\n",
    "test['class'] = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_margin_list = []\n",
    "\n",
    "for i in range(0,100):\n",
    "    threshold = i*1.0 / 100\n",
    "    test['pred_class'] = (test['pred']>= threshold).astype(int)\n",
    "    tp_revenue = np.sum((test['pred_class']==1).astype(int) * (test['class']==1).astype(int) * (test['loan_int_rate']/100)*test['loan_amnt'])\n",
    "    fn_lost = -np.sum((test['pred_class']==0).astype(int) * (test['class']==1).astype(int) * (test['loan_int_rate']/100)*test['loan_amnt'])\n",
    "    fp_lost = test[(test['pred_class']==1) & (test['class']==0)].shape[0] * fp\n",
    "    tn_revenue = test[(test['pred_class']==0) & (test['class']==0)].shape[0] * tn \n",
    "    total_margin = tp_revenue + fn_lost + fp_lost + tn_revenue\n",
    "    total_margin_list.append(total_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_margin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,100),total_margin_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = total_margin_list.index(max(total_margin_list))/100\n",
    "cut_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt część II\n",
    "Do realizacji jako ostatnia część bloku\n",
    "\n",
    "1. Zapisz model do pliku, a następnie go pobierz.\n",
    "2. Zapisz ramkę danych do lokalnej bazy danych.\n",
    "3. Pobierz ramkę dla kilku rekordów i dokonaj predykcji. Napisz funkcje do pobierania odpowiednich danych oraz do predykcji. \n",
    "4. Zapisz model do MLflow.\n",
    "5. Wytrenuj dowolny, inny model i zapisz go do MLflow.\n",
    "6. Porównaj wyniki modeli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zapisz model do pliku, a następnie go pobierz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model,'models/gb_credit_approve.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('models/gb_credit_approve.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Zapisz ramkę danych do lokalnej bazy danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = os.getenv('DB')\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('model_data_credit',con=engine, if_exists='append',method= 'multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pobierz ramkę dla kilku rekordów i dokonaj predykcji. Napisz funkcje do pobierania odpowiednich danych oraz do predykcji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = 'person_age >=60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(engine: sqlalchemy.engine.base.Engine, conditions: str):\n",
    "    \"\"\"\n",
    "    Function to import data from database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        to_pred = pd.read_sql(f\"\"\"select * \n",
    "                              from model_data_credit where {conditions} \"\"\", con= engine)\n",
    "    except:\n",
    "        print(\"Nie udało się pobrać danych dla zadanych warunków\")\n",
    "    if to_pred.shape[0]==0:\n",
    "        raise BaseException(\"Brak danych dla podanych ograniczeń\")\n",
    "    return to_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pred = data_load(engine=engine, conditions=cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(df: pd.DataFrame, \n",
    "                     model_path: str,\n",
    "                     encoding_path: str):\n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "    except:\n",
    "        print('Brak modelu')\n",
    "    try:\n",
    "        encoding = joblib.load(encoding_path)\n",
    "    except:\n",
    "        print('Brak encodingu')\n",
    "    encoded = pd.DataFrame(data= encoding.transform(df[encoding.feature_names_in_]),columns = encoding.get_feature_names_out())\n",
    "    df = df.join(encoded)\n",
    "    preds = model.predict(df[model.feature_names_in_])\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(ohe,'models/ohe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_prediction(to_pred, model_path='models/gb_credit_approve.joblib', encoding_path='models/ohe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Zapisz model do MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiersz polecenia : mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri = 'http://127.0.0.1:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('credit acceptance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    for key, value in  model.get_params().items():\n",
    "        mlflow.log_param(key, value)\n",
    "    mlflow.log_metric('auc_train', auc_train)\n",
    "    mlflow.log_metric('auc_test',auc_test)\n",
    "    signature = mlflow.models.infer_signature(model_input = train_x,\n",
    "                                              model_output = ((train_pred >=0.04).astype(int)))\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model = model,\n",
    "        artifact_path = 'credits approval',\n",
    "        signature = signature,\n",
    "        input_example = train_x,\n",
    "        registered_model_name  = 'credits approval new'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Wytrenuj dowolny, inny model i zapisz go do MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2= HistGradientBoostingClassifier().fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model_2.predict_proba(train_x)[:,1]\n",
    "test_pred = model_2.predict_proba(test_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_train = roc_auc_score(train_y, train_pred)\n",
    "auc_test = roc_auc_score(test_y,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Porównaj wyniki modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    for key, value in  model_2.get_params().items():\n",
    "        mlflow.log_param(key, value)\n",
    "    mlflow.log_metric('auc_train', auc_train)\n",
    "    mlflow.log_metric('auc_test',auc_test)\n",
    "    signature = mlflow.models.infer_signature(model_input = train_x,\n",
    "                                              model_output = model_2.predict(train_x))\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model = model_2,\n",
    "        artifact_path = 'credits approval',\n",
    "        signature = signature,\n",
    "        input_example = train_x,\n",
    "        registered_model_name  = 'credits approval hist GB'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
